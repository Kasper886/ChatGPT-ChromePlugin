import asyncio
import logging
import openai
import os
import re
import subprocess
from pydub import AudioSegment
from datetime import datetime
from aiogram import Bot, Dispatcher, Router, types
from aiogram.types import Message, CallbackQuery, InlineKeyboardMarkup, InlineKeyboardButton
from aiogram.filters import Command, CommandStart
from aiogram.enums import ChatType, ContentType
from dotenv import load_dotenv
from models_list import AVAILABLE_MODELS  # Import available models from an external file

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler(), logging.FileHandler("bot.log")]
)
logger = logging.getLogger(__name__)

# === –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ===
load_dotenv()
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_BOT_TOKEN:
    raise ValueError("TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")

bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()
router = Router()  # –î–æ–±–∞–≤–ª—è–µ–º Router
openai.api_key = OPENAI_API_KEY

# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ===
#SELECTED_MODEL_FILE = "selected_model.txt"
DEFAULT_MODEL = "gpt-3.5-turbo"
#current_chat_file = None

# ==== –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ====
async def get_selected_model_file(username: str) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    return f"{username}-selected_model.txt"

async def create_new_chat_file(username: str) -> str:
    """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π —Ñ–∞–π–ª —á–∞—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –∏–º—è."""
    selected_model_file = await get_selected_model_file(username)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ —á–∞—Ç–∞
    timestamp = datetime.now().strftime("%d-%m-%y-%H-%M-%S")
    chat_file = f"{username}-chat-{timestamp}.txt"

    # –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏ –Ω–µ—Ç ‚Äî —Å–æ–∑–¥–∞–µ–º –µ–≥–æ
    if not os.path.exists(selected_model_file):
        with open(selected_model_file, "w", encoding="utf-8") as f:
            f.write("gpt-3.5-turbo\n")  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º gpt-3.5-turbo

    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ñ–∞–π–ª —á–∞—Ç–∞
    with open(chat_file, "w", encoding="utf-8") as f:
        f.write("Chat started\n")

    logger.info(f"‚úÖ –ù–æ–≤—ã–π —Ñ–∞–π–ª —á–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω: {chat_file}")
    return chat_file

async def append_to_chat_file(username: str, text: str):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –≤ —Ñ–∞–π–ª —á–∞—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π (–∞–∫—Ç–∏–≤–Ω—ã–π) —Ñ–∞–π–ª —á–∞—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    chat_files = sorted([f for f in os.listdir() if f.startswith(f"{username}-chat")], reverse=True)

    if not chat_files:
        return  # –ï—Å–ª–∏ —á–∞—Ç–æ–≤ –Ω–µ—Ç, –Ω–µ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º

    chat_file = chat_files[0]  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–æ–∑–¥–∞–Ω–Ω—ã–π —á–∞—Ç

    with open(chat_file, "a", encoding="utf-8") as f:
        f.write(text + "\n")


async def save_selected_model(username: str, model_name: str = DEFAULT_MODEL):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –≤ —Ñ–∞–π–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞ - –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."""
    selected_model_file = await get_selected_model_file(username)
    
    with open(selected_model_file, "w", encoding="utf-8") as f:
        f.write(model_name)  # –¢–µ–ø–µ—Ä—å –∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç
    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å '{model_name}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ñ–∞–π–ª: {selected_model_file}")

async def load_selected_model(username: str):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç ‚Äî —Å–æ–∑–¥–∞–µ—Ç –µ–≥–æ —Å –º–æ–¥–µ–ª—å—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."""
    selected_model_file = await get_selected_model_file(username)

    if not os.path.exists(selected_model_file):
        await save_selected_model(username, DEFAULT_MODEL)  # –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º –µ–≥–æ —Å –º–æ–¥–µ–ª—å—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        return DEFAULT_MODEL

    with open(selected_model_file, "r", encoding="utf-8") as f:
        model = f.read().strip()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å, –∏–Ω–∞—á–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    if model not in AVAILABLE_MODELS:
        return DEFAULT_MODEL

    return model

# === –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π ===
def clean_transcribed_message(text: str) -> str:
    """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ."""
    patterns_to_remove = [
        r"–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç .+?:",  # –£–±–∏—Ä–∞–µ–º –∏–º—è –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è
        r"–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ$",  # –ü—Ä–æ—Å—Ç–æ "–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"
    ]
    
    for pattern in patterns_to_remove:
        text = re.sub(pattern, "", text).strip()

    return text if text else None


# === –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ ===
@router.message(CommandStart())
async def cmd_start(message: Message):
    await message.answer(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –¥–ª—è –æ–±—â–µ–Ω–∏—è —Å ChatGPT.\n\n"
        "ü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n"
        "/startnewchat - –ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π —á–∞—Ç\n"
        "/setmodel - –í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å\n"
        "/currentmodel - –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å"
    )

@router.message(Command("startnewchat"))
async def start_new_chat(message: Message):
    username = message.from_user.username or f"user_{message.from_user.id}"
    chat_file = await create_new_chat_file(username)  # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π —á–∞—Ç-—Ñ–∞–π–ª

    await message.answer(f"‚úÖ –ù–æ–≤—ã–π —á–∞—Ç —Å–æ–∑–¥–∞–Ω!\n–§–∞–π–ª: `{chat_file}`")


@router.message(Command("currentmodel"))
async def current_model(message: Message):
    username = message.from_user.username or f"user_{message.from_user.id}"  # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    selected_model = await load_selected_model(username)  # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    
    if not selected_model:  # –ï—Å–ª–∏ —Ñ–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–æ–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        selected_model = "gpt-3.5-turbo"

    await message.answer(f"üõ† –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: `{selected_model}`")


@router.message(Command("setmodel"))
async def set_model_command(message: Message):
    buttons = []
    row = []
    for i, model in enumerate(AVAILABLE_MODELS):
        row.append(InlineKeyboardButton(text=model, callback_data=f"setmodel_{model}"))
        if len(row) == 2 or i == len(AVAILABLE_MODELS) - 1:
            buttons.append(row)
            row = []

    keyboard = InlineKeyboardMarkup(inline_keyboard=buttons)
    username = message.from_user.username or f"user_{message.from_user.id}"  # –ï—Å–ª–∏ username –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º user_ID
    selected_model_file = await get_selected_model_file(username)
    await message.answer(f"Select a model:\n(Saving to: `{selected_model_file}`)", reply_markup=keyboard)


@router.callback_query(lambda c: c.data.startswith("setmodel_"))
async def model_selected(callback_query: CallbackQuery):
    model_name = callback_query.data.split("_")[1]  # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    username = callback_query.from_user.username or f"user_{callback_query.from_user.id}"  # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è

    await save_selected_model(username, model_name)  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤—ã–∑–æ–≤

    await callback_query.answer(f"‚úÖ –ú–æ–¥–µ–ª—å '{model_name}' –≤—ã–±—Ä–∞–Ω–∞!")
    await callback_query.message.edit_text(f"üîπ –í–∞—à–∞ —Ç–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: `{model_name}`")

async def transcribe_audio(audio_path: str) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é OpenAI Whisper API (–Ω–æ–≤—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å)."""
    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º OGG –≤ MP3
        audio = AudioSegment.from_ogg(audio_path)
        mp3_path = audio_path.replace(".ogg", ".mp3")
        audio.export(mp3_path, format="mp3")

        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ OpenAI API (–Ω–æ–≤—ã–π —Å–ø–æ—Å–æ–±)
        client = openai.OpenAI(api_key=OPENAI_API_KEY)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
        with open(mp3_path, "rb") as audio_file:
            response = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file
            )

        return response.text

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∞—É–¥–∏–æ: {e}")
        return None

#@router.message() 
async def chat_with_gpt(message: Message):
    try:
        user_message = message.text.strip()
        if not user_message:
            await message.reply("‚ùå –ü—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
            return

        selected_model = await load_selected_model()

        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        response = client.chat.completions.create(
            model=selected_model,
            messages=[{"role": "user", "content": user_message}]
        )

        bot_response = response.choices[0].message.content
        await append_to_chat_file(f"User: {user_message}\nBot: {bot_response}")
        await message.reply(bot_response)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ chat_with_gpt: {str(e)}")
        await message.reply("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è.")

async def chat_with_gpt_file(message: Message):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª —á–∞—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ GPT –∏ –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç."""
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        username = message.from_user.username or f"user_{message.from_user.id}"

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã —á–∞—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        chat_files = sorted([f for f in os.listdir() if f.startswith(f"{username}-chat")], reverse=True)

        # –ï—Å–ª–∏ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤ —á–∞—Ç–æ–≤ ‚Äî –æ–Ω –Ω–µ –º–æ–∂–µ—Ç –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
        if not chat_files:
            return "‚ùå –£ –≤–∞—Å –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —á–∞—Ç–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –Ω–æ–≤—ã–π —á–∞—Ç –∫–æ–º–∞–Ω–¥–æ–π /startnewchat."

        # –ë–µ—Ä–µ–º —Å–∞–º—ã–π –Ω–æ–≤—ã–π —Ñ–∞–π–ª —á–∞—Ç–∞
        chat_file = chat_files[0]

        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ —á–∞—Ç–∞
        with open(chat_file, "r", encoding="utf-8") as f:
            chat_history = f.read()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        selected_model = await load_selected_model(username)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–æ–ø—É—Å—Ç–∏–º–æ–π
        if selected_model not in AVAILABLE_MODELS:
            selected_model = "gpt-3.5-turbo"  # –ï—Å–ª–∏ —Ñ–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞, —Å—Ç–∞–≤–∏–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ GPT
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        response = client.chat.completions.create(
            model=selected_model,
            messages=[{"role": "system", "content": "–¢—ã ‚Äî —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫."},
                      {"role": "user", "content": chat_history},
                      {"role": "user", "content": message.text}]  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –¥–∏–∞–ª–æ–≥
        )

        bot_response = response.choices[0].message.content.strip()

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –æ—Ç–≤–µ—Ç –±–æ—Ç–∞ –≤ —Ñ–∞–π–ª —á–∞—Ç–∞
        with open(chat_file, "a", encoding="utf-8") as f:
            f.write(f"\nUser: {message.text}\nBot: {bot_response}")

        return f"ü§ñ **[–ú–æ–¥–µ–ª—å: {selected_model}]**\n\n{bot_response}"

    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ GPT: {e}"

@router.message()
async def handle_messages(message: Message):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∏ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤ —á–∞—Ç-—Ñ–∞–π–ª –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ GPT."""
    username = message.from_user.username or f"user_{message.from_user.id}"

    # –ò—â–µ–º —Ñ–∞–π–ª—ã —á–∞—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    chat_files = sorted([f for f in os.listdir() if f.startswith(f"{username}-chat")], reverse=True)

    # –ï—Å–ª–∏ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —á–∞—Ç–∞, –æ–Ω –Ω–µ –º–æ–∂–µ—Ç –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
    if message.content_type == ContentType.TEXT and not chat_files:
        await message.answer("‚ùå –£ –≤–∞—Å –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —á–∞—Ç–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –Ω–æ–≤—ã–π —á–∞—Ç –∫–æ–º–∞–Ω–¥–æ–π /startnewchat.")
        return

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π (–∞–∫—Ç–∏–≤–Ω—ã–π) —Ñ–∞–π–ª —á–∞—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    chat_file = chat_files[0] if chat_files else None

    # üé§ –ï—Å–ª–∏ –ø—Ä–∏—à–ª–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    if message.content_type == ContentType.VOICE:
        logger.info("üé§ –ü–æ–ª—É—á–µ–Ω–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º...")

        try:
            # –°–∫–∞—á–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            voice_file = await bot.get_file(message.voice.file_id)
            voice_path = f"{voice_file.file_id}.ogg"
            await bot.download_file(voice_file.file_path, voice_path)

            # –†–∞—Å–ø–æ–∑–Ω–∞—ë–º —Ç–µ–∫—Å—Ç
            text = await transcribe_audio(voice_path)

            if text:
                logger.info(f"‚úÖ –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {text}")

                # –£–±–∏—Ä–∞–µ–º "–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ:"
                cleaned_text = text.replace("–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ:", "").strip()

                # üì¢ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —á–∞—Ç —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                await message.reply(f"üéô –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n{cleaned_text}")

                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ñ–∞–π–ª —á–∞—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                await append_to_chat_file(username, f"User: {cleaned_text}")

                # üîç –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
                selected_model = await load_selected_model(username)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
                if selected_model not in AVAILABLE_MODELS:
                    logger.warning(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –º–æ–¥–µ–ª—å '{selected_model}', –∏—Å–ø–æ–ª—å–∑—É–µ–º gpt-3.5-turbo")
                    selected_model = "gpt-3.5-turbo"

                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ GPT
                client = openai.OpenAI(api_key=OPENAI_API_KEY)
                response = client.chat.completions.create(
                    model=selected_model,
                    messages=[
                        {"role": "system", "content": "–¢—ã ‚Äî —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫."},
                        {"role": "user", "content": cleaned_text}
                    ]
                )

                bot_response = response.choices[0].message.content.strip()

                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –æ—Ç–≤–µ—Ç –±–æ—Ç–∞ –≤ —Ñ–∞–π–ª —á–∞—Ç–∞
                await append_to_chat_file(username, f"Bot: {bot_response}")

                await message.reply(f"ü§ñ **[–ú–æ–¥–µ–ª—å: {selected_model}]**\n\n{bot_response}")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
            await message.reply("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.")

        return  # –ó–∞–≤–µ—Ä—à–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è

    # üìÑ –ï—Å–ª–∏ –ø—Ä–∏—à–ª–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    user_message = message.text.strip()
    if user_message:
        await append_to_chat_file(username, f"User: {user_message}")

        if chat_file:
            response = await chat_with_gpt_file(message)  # –î–∏–∞–ª–æ–≥
        else:
            response = await chat_with_gpt(message)  # –û–¥–∏–Ω–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç

        await message.reply(response)

# === –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ ===
dp.include_router(router)

async def main():
    logger.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
    await dp.start_polling(bot)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        logger.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")