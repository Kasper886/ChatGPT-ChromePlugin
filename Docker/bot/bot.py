import asyncio
import logging
import openai
import os
from datetime import datetime
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton, CallbackQuery
from aiogram.filters import Command, CommandStart
from aiogram.enums import ChatType, ContentType
from dotenv import load_dotenv
from models_list import AVAILABLE_MODELS  # –ü–æ–¥–∫–ª—é—á–∏—Ç–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ —Ñ–∞–π–ª–∞ models_list.py

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(), logging.FileHandler('bot.log')]
)
logger = logging.getLogger(__name__)

# === –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ===
load_dotenv()
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_BOT_TOKEN:
    raise ValueError("TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")

bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()
openai.api_key = OPENAI_API_KEY

# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ===
SELECTED_MODEL_FILE = "selected_model.txt"
DEFAULT_MODEL = "gpt-3.5-turbo"
current_chat_file = None

# ==== –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ====
async def create_new_chat_file():
    global current_chat_file
    timestamp = datetime.now().strftime("chat-%d-%m-%y-%H-%M-%S.txt")
    current_chat_file = timestamp
    with open(current_chat_file, "w", encoding='utf-8') as f:
        f.write("Chat started\n")
    logger.info(f"–ù–æ–≤—ã–π —Ñ–∞–π–ª —á–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω: {current_chat_file}")

async def append_to_chat_file(text):
    if current_chat_file:
        with open(current_chat_file, "a", encoding='utf-8') as f:
            f.write(text + "\n")

async def save_selected_model(model_name):
    with open(SELECTED_MODEL_FILE, "w", encoding='utf-8') as f:
        f.write(model_name)
    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_name}")

async def load_selected_model():
    if os.path.exists(SELECTED_MODEL_FILE):
        with open(SELECTED_MODEL_FILE, "r", encoding='utf-8') as f:
            model = f.read().strip()
            if model in AVAILABLE_MODELS:
                return model
    return DEFAULT_MODEL

def clean_message(text: str) -> str:
    """
    –û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ñ—Ä–∞–∑ (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ¬ª).
    """
    unwanted_phrases = ["–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ", "Voice message", "–ê—É–¥–∏–æ—Å–æ–æ–±—â–µ–Ω–∏–µ", "Audio message"]
    for phrase in unwanted_phrases:
        text = text.replace(phrase, "").strip()
    return text if text != "" else None

# === –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ ===
@dp.message(CommandStart())
async def cmd_start(message: Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /startnewchat –¥–ª—è –Ω–∞—á–∞–ª–∞ –Ω–æ–≤–æ–≥–æ —á–∞—Ç–∞.")

@dp.message(Command("startnewchat"))
async def start_new_chat(message: Message):
    await create_new_chat_file()
    timestamp = datetime.now().strftime("%d.%m.%Y %H:%M:%S")
    await message.answer(f"üÜï –ù–æ–≤—ã–π —á–∞—Ç –Ω–∞—á–∞—Ç: {timestamp}")

@dp.message(Command("setmodel"))
async def set_model_command(message: Message):
    buttons = []
    row = []
    for i, model in enumerate(AVAILABLE_MODELS):
        row.append(InlineKeyboardButton(text=model, callback_data=f"setmodel_{model}"))
        if len(row) == 2 or i == len(AVAILABLE_MODELS) - 1:
            buttons.append(row)
            row = []
    
    keyboard = InlineKeyboardMarkup(inline_keyboard=buttons)
    await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:", reply_markup=keyboard)

@dp.callback_query(lambda c: c.data.startswith('setmodel_'))
async def model_selected(callback_query: CallbackQuery):
    model_name = callback_query.data.replace("setmodel_", "")
    if model_name in AVAILABLE_MODELS:
        await save_selected_model(model_name)
        await callback_query.message.edit_text(f"‚úÖ –ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: {model_name}")
        logger.info(f"–ú–æ–¥–µ–ª—å –≤—ã–±—Ä–∞–Ω–∞: {model_name}")
    else:
        await callback_query.answer("‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏", show_alert=True)

@dp.message(Command("currentmodel"))
async def current_model(message: Message):
    selected_model = await load_selected_model()
    await message.answer(f"üõ† –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {selected_model}")

# === –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π ===
async def chat_with_gpt(message: Message):
    try:
        if message.chat.type != ChatType.PRIVATE:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –≥—Ä—É–ø–ø
            if message.is_automatic_forward or message.forward_from:
                return
        
        user_message = clean_message(message.text)
        if not user_message:
            if message.chat.type == ChatType.PRIVATE:
                await message.answer("‚ùå –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
            return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª —á–∞—Ç–∞
        if not current_chat_file or not os.path.exists(current_chat_file):
            await message.answer("‚ùå –ù–∞—á–Ω–∏—Ç–µ –Ω–æ–≤—ã–π —á–∞—Ç –∫–æ–º–∞–Ω–¥–æ–π /startnewchat")
            return

        selected_model = await load_selected_model()
        client = openai.OpenAI(api_key=OPENAI_API_KEY)

        # –ß–∏—Ç–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–æ–≤
        messages = []
        if current_chat_file:
            with open(current_chat_file, "r", encoding='utf-8') as f:
                for line in f:
                    if line.startswith("User:"):
                        content = clean_message(line.replace("User: ", "").strip())
                        if content:
                            messages.append({"role": "user", "content": content})
                    elif line.startswith("Bot:"):
                        messages.append({"role": "assistant", "content": line.replace("Bot: ", "").strip()})
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        messages.append({"role": "user", "content": user_message})
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ ChatGPT
        response = client.chat.completions.create(
            model=selected_model,
            messages=messages
        )
        bot_response = response.choices[0].message.content
        await append_to_chat_file(f"User: {user_message}")
        await append_to_chat_file(f"Bot: {bot_response}")
        await message.answer(bot_response)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ chat_with_gpt: {str(e)}")
        if message.chat.type == ChatType.PRIVATE:
            await message.answer("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

@dp.message()
async def handle_messages(message: Message):
    if message.content_type == ContentType.TEXT and not message.text.startswith('/'):
        await chat_with_gpt(message)

# === –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ ===
async def main():
    logger.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
    await dp.start_polling(bot)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        logger.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
