import asyncio
import logging
import openai
import os
import re
import glob
from datetime import datetime, timedelta
from aiogram import Bot, Dispatcher, Router, types
from aiogram.types import Message, CallbackQuery, InlineKeyboardMarkup, InlineKeyboardButton
from aiogram.filters import Command, CommandStart
from aiogram.enums import ContentType
from dotenv import load_dotenv
from pydub import AudioSegment
from models_list import AVAILABLE_MODELS  # Import available models from an external file

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler(), logging.FileHandler("bot.log")]
)
logger = logging.getLogger(__name__)

# === –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ===
load_dotenv()
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_BOT_TOKEN:
    raise ValueError("TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")

bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()
router = Router()
openai.api_key = OPENAI_API_KEY

# === –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ===
DEFAULT_MODEL = "gpt-3.5-turbo"
user_chat_files = {}
SELECTED_MODEL_FILE = "selected_model.txt"

# ==== –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ ====
def cleanup_old_files():
    """–£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª—ã —á–∞—Ç–æ–≤ –∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª—ã —Å—Ç–∞—Ä—à–µ 10 –¥–Ω–µ–π."""
    now = datetime.now()
    cutoff = now - timedelta(days=10)
    
    for file in glob.glob("*-chat-*.txt") + glob.glob("*.ogg"):
        file_time = datetime.fromtimestamp(os.path.getmtime(file))
        if file_time < cutoff:
            os.remove(file)
            logger.info(f"–£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: {file}")

cleanup_old_files()

# ==== –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ====
async def create_new_chat_file(user: types.User):
    """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π —Ñ–∞–π–ª —á–∞—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    timestamp = datetime.now().strftime("%d-%m-%y-%H-%M-%S")
    filename = f"{user.username or user.id}-chat-{timestamp}.txt"
    user_chat_files[user.id] = filename
    with open(filename, "w", encoding="utf-8") as f:
        f.write("Chat started\n")
    logger.info(f"–°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª —á–∞—Ç–∞: {filename}")
    return filename

async def get_chat_file(user: types.User):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª —á–∞—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ None, –µ—Å–ª–∏ –æ–Ω –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
    files = glob.glob(f"{user.username or user.id}-chat-*.txt")
    return files[0] if files else None

async def append_to_chat_file(user: types.User, text: str):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –≤ —Ñ–∞–π–ª —á–∞—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    chat_file = await get_chat_file(user)
    if chat_file:
        with open(chat_file, "a", encoding="utf-8") as f:
            f.write(text + "\n")

async def save_selected_model(model_name):
    with open(SELECTED_MODEL_FILE, "w", encoding="utf-8") as f:
        f.write(model_name)
    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_name}")

async def load_selected_model():
    if os.path.exists(SELECTED_MODEL_FILE):
        with open(SELECTED_MODEL_FILE, "r", encoding="utf-8") as f:
            model = f.read().strip()
            if model:
                return model
    return DEFAULT_MODEL

async def transcribe_audio(audio_path: str) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é OpenAI Whisper API (–Ω–æ–≤—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å)."""
    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º OGG –≤ MP3
        audio = AudioSegment.from_ogg(audio_path)
        mp3_path = audio_path.replace(".ogg", ".mp3")
        audio.export(mp3_path, format="mp3")

        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ OpenAI API (–Ω–æ–≤—ã–π —Å–ø–æ—Å–æ–±)
        client = openai.OpenAI(api_key=OPENAI_API_KEY)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
        with open(mp3_path, "rb") as audio_file:
            response = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file
            )

        return response.text

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∞—É–¥–∏–æ: {e}")
        return None

async def chat_with_gpt(user: types.User, text: str) -> str:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ ChatGPT –∏ –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç."""
    try:
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        response = client.chat.completions.create(
            model=DEFAULT_MODEL,
            messages=[{"role": "user", "content": text}]
        )
        bot_response = response.choices[0].message.content
        await append_to_chat_file(user, f"Bot: {bot_response}")
        return bot_response
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ chat_with_gpt: {e}")
        return "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è."

# ==== –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ ====
@router.message(CommandStart())
async def cmd_start(message: Message):
    await message.answer(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –¥–ª—è –æ–±—â–µ–Ω–∏—è —Å ChatGPT.\n\n"
        "ü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n"
        "/startnewchat - –ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π —á–∞—Ç\n"
        "/setmodel - –í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å\n"
        "/currentmodel - –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å"
    )

@router.message(Command("currentmodel"))
async def current_model(message: Message):
    selected_model = await load_selected_model()
    await message.answer(f"üõ† –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {selected_model}")

@router.message(Command("setmodel"))
async def set_model_command(message: Message):
    buttons = []
    row = []
    for i, model in enumerate(AVAILABLE_MODELS):
        row.append(InlineKeyboardButton(text=model, callback_data=f"setmodel_{model}"))
        if len(row) == 2 or i == len(AVAILABLE_MODELS) - 1:
            buttons.append(row)
            row = []

    keyboard = InlineKeyboardMarkup(inline_keyboard=buttons)
    await message.answer("Select a model:", reply_markup=keyboard)

@router.callback_query()
async def model_selected(callback_query: CallbackQuery):
    model_name = callback_query.data.replace("setmodel_", "")
    if model_name in AVAILABLE_MODELS:
        await save_selected_model(model_name)
        await callback_query.message.edit_text(f"‚úÖ –ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: {model_name}")
    else:
        await callback_query.answer("‚ùå –û—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏.", show_alert=True)

@router.message(Command("startnewchat"))
async def start_new_chat(message: Message):
    filename = await create_new_chat_file(message.from_user)
    await message.answer(f"üÜï –ù–æ–≤—ã–π —á–∞—Ç –Ω–∞—á–∞—Ç. –§–∞–π–ª: {filename}")

# ==== –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π ====
async def chat_with_gpt(message: Message):
    try:
        user_message = message.text.strip()
        if not user_message:
            await message.reply("‚ùå –ü—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
            return

        selected_model = await load_selected_model()

        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        response = client.chat.completions.create(
            model=selected_model,
            messages=[{"role": "user", "content": user_message}]
        )

        bot_response = response.choices[0].message.content
        await append_to_chat_file(f"User: {user_message}\nBot: {bot_response}")
        await message.reply(bot_response)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ chat_with_gpt: {str(e)}")
        await message.reply("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è.")

async def chat_with_gpt_file():
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤–µ—Å—å —Ñ–∞–π–ª —á–∞—Ç–∞ –≤ GPT –∏ –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç."""
    try:
        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ —á–∞—Ç–∞
        if not user_chat_files:
            return "‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª —á–∞—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω."

        with open(user_chat_files, "r", encoding="utf-8") as f:
            chat_history = f.read()

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ GPT
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        response = client.chat.completions.create(
            model="gpt-4o",  # –ú–æ–∂–Ω–æ —Å–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω—É–∂–Ω—É—é –º–æ–¥–µ–ª—å
            messages=[{"role": "system", "content": "–¢—ã ‚Äî —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫."},
                      {"role": "user", "content": chat_history}]
        )

        bot_response = response.choices[0].message.content

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç GPT –≤ —Ñ–∞–π–ª —á–∞—Ç–∞
        await append_to_chat_file(f"Bot: {bot_response}")

        return bot_response

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ chat_with_gpt_file: {e}")
        return "‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è."

# === –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ ===
dp.include_router(router)

async def main():
    logger.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
    await dp.start_polling(bot)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        logger.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")