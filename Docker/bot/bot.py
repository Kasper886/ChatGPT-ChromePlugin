import asyncio
import logging
import openai
import os
from datetime import datetime
from flask import Flask, request, jsonify
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message, ReplyKeyboardRemove, InlineKeyboardMarkup, InlineKeyboardButton
from aiogram.filters import Command
from aiogram.enums import ChatType
from aiogram.types import ContentType
from dotenv import load_dotenv
from models_list import AVAILABLE_MODELS  # Import available models from an external file

# Load environment variables
load_dotenv()

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()
app = Flask(__name__)

openai.api_key = OPENAI_API_KEY

# File to store the selected model persistently
SELECTED_MODEL_FILE = "selected_model.txt"
DEFAULT_MODEL = "gpt-3.5-turbo"  # Default model if no file exists

# Logging configuration
logging.basicConfig(level=logging.INFO)

# Global variable to track current chat file
current_chat_file = None

def create_new_chat_file():
    global current_chat_file
    timestamp = datetime.now().strftime("chat-%d-%m-%y-%H-%M-%S.txt")
    current_chat_file = timestamp
    with open(current_chat_file, "w") as f:
        f.write("Chat started\n")
    logging.info(f"New chat file created: {current_chat_file}")

def append_to_chat_file(text):
    if current_chat_file:
        with open(current_chat_file, "a") as f:
            f.write(text + "\n")

def save_selected_model(model_name):
    try:
        with open(SELECTED_MODEL_FILE, "w") as f:
            f.write(model_name)
        logging.info(f"‚úÖ Model {model_name} saved.")
    except Exception as e:
        logging.error(f"‚ùå Error saving model: {str(e)}")

def load_selected_model():
    try:
        if os.path.exists(SELECTED_MODEL_FILE):
            with open(SELECTED_MODEL_FILE, "r") as f:
                model = f.read().strip()
                if model in AVAILABLE_MODELS:
                    return model
        return DEFAULT_MODEL
    except Exception as e:
        logging.error(f"‚ùå Error loading model: {str(e)}")
        return DEFAULT_MODEL

selected_model = load_selected_model()

async def chat_with_gpt(message: Message):
    try:
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        logging.info(f"üìù DEBUG: Message type: {message.content_type}")
        logging.info(f"üìù DEBUG: Full message object: {message}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø —Å–æ–æ–±—â–µ–Ω–∏—è
        if message.content_type != 'text':
            logging.info(f"‚ö†Ô∏è Received non-text message: {message.content_type}")
            await message.answer("‚ùå –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")
            return # –ó–∞–≤–µ—Ä—à–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏

        if not message.text:
            logging.info("‚ö†Ô∏è Received empty text message")
            await message.answer("‚ùå –°–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞")
            return # –ó–∞–≤–µ—Ä—à–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏

        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥—è—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        logging.info(f"üìù DEBUG: Incoming message: {message.text}")
        
        # –û—á–∏—â–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        user_message = clean_message(message.text)
        logging.info(f"üìù DEBUG: Cleaned message: {user_message}")

        if not user_message:
            await message.answer("‚ùå –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞")
            return # –ó–∞–≤–µ—Ä—à–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª —á–∞—Ç–∞
        if not current_chat_file or not os.path.exists(current_chat_file):
            await message.answer("‚ùå Please start a new chat with /startnewchat")
            return  # –ó–∞–≤–µ—Ä—à–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å
        selected_model = load_selected_model()
        logging.info(f"üìù DEBUG: Sending request to ChatGPT with model: {selected_model} and message: {user_message}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º OpenAI-–∫–ª–∏–µ–Ω—Ç
        client = openai.OpenAI(api_key=OPENAI_API_KEY)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
        messages = []
        if current_chat_file and os.path.exists(current_chat_file):
            with open(current_chat_file, "r") as f:
                for line in f:
                    if line.startswith("User:"):
                        content = clean_message(line.replace("User: ", "").strip())
                        if content:
                            messages.append({"role": "user", "content": content})
                    elif line.startswith("Bot:"):
                        content = clean_message(line.replace("Bot: ", "").strip())
                        if content:
                            messages.append({"role": "assistant", "content": content})

        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        messages.append({"role": "user", "content": user_message})

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –≤ ChatGPT
        response = client.chat.completions.create(
            model=selected_model,
            messages=messages
        )

        actual_model = response.model
        bot_response = response.choices[0].message.content

        logging.info(f"‚úÖ DEBUG: Used model: {actual_model}")
        reply_text = f"(üîπ Real Model ID: {actual_model})\n{bot_response}"

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∏–∞–ª–æ–≥ –≤ —Ñ–∞–π–ª
        append_to_chat_file(f"User: {user_message}")
        append_to_chat_file(f"Bot: {bot_response}")

        # –û—Ç–≤–µ—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        await message.answer(reply_text)

    except Exception as e:
        logging.error(f"‚ùå ERROR in chat_with_gpt: {str(e)}")
        await message.answer(f"Error: {str(e)}")


async def start(message: Message):
    await message.answer(f"Please select a model with /setmodel (current model is gpt-3.5 turbo) and start a new chat with /startnewchat")

async def start_new_chat(message: Message):
    create_new_chat_file()
    timestamp = datetime.now().strftime("%d.%m.%Y %H.%M.%S")
    await message.answer(f"üÜï New session with ChatGPT {timestamp}")

async def current_model(message: Message):
    selected_model = load_selected_model()
    await message.answer(f"üõ† Current model: {selected_model}")

def set_model_command(message: Message):
    # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–Ω–æ–ø–æ–∫ –ø–æ 2 –≤ —Ä—è–¥
    buttons = []
    row = []
    for i, model in enumerate(AVAILABLE_MODELS):
        row.append(InlineKeyboardButton(text=model, callback_data=f"setmodel_{model}"))
        if len(row) == 2 or i == len(AVAILABLE_MODELS) - 1:
            buttons.append(row)
            row = []

    keyboard = InlineKeyboardMarkup(inline_keyboard=buttons)
    return message.answer("Select a model:", reply_markup=keyboard)

async def model_selected(callback_query: types.CallbackQuery):
    model_name = callback_query.data.replace("setmodel_", "")
    if model_name in AVAILABLE_MODELS:
        save_selected_model(model_name)
        global selected_model
        selected_model = model_name
        await callback_query.message.edit_text(f"‚úÖ Model changed to: {model_name}")
    else:
        await callback_query.answer("‚ùå Invalid model selection.", show_alert=True)

def clean_message(text: str) -> str:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –∏ –æ—á–∏—â–∞–µ—Ç –≤—Ö–æ–¥—è—â–∏–π —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ñ—Ä–∞–∑
    –∏–ª–∏ –Ω–µ–Ω—É–∂–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ¬ª).
    """
    if not text:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –ø—É—Å—Ç–æ–µ
        return ""

    # –£–±–∏—Ä–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Ñ—Ä–∞–∑—ã (–º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥—Ä—É–≥–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞)
    unwanted_phrases = [
        "–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",  # –ü—Ä–∏–º–µ—Ä: —Ñ—Ä–∞–∑–∞ –æ—Ç SaluteSpeechBot
        "Voice message",        # –ï—Å–ª–∏ –µ—Å—Ç—å –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
        "–ê—É–¥–∏–æ—Å–æ–æ–±—â–µ–Ω–∏–µ",       # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º
        "Audio message"         # –í–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º
    ]

    # –£–±–∏—Ä–∞–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Ñ—Ä–∞–∑—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞
    for phrase in unwanted_phrases:
        text = text.replace(phrase, "").strip()

    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏–ª–∏ —Å—Å—ã–ª–∫–∏ (–µ—Å–ª–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç)
    text = text.strip('@').strip()  # –û—á–∏—Å—Ç–∫–∞ –æ—Ç "@" –∏–ª–∏ –¥—Ä—É–≥–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (–∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å)
    return text if text else ""

'''
# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
@dp.message()
async def handle_messages(message: Message):
    try:
        if message.content_type == ContentType.VOICE:
            logging.info("üé§ Received voice message")
            await message.answer("–Ø –ø–æ–∫–∞ –Ω–µ —É–º–µ—é –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è")
            return
            
        elif message.content_type == ContentType.STICKER:
            logging.info("üéØ Received sticker")
            await message.answer("–Ø –ø–æ–∫–∞ –Ω–µ —É–º–µ—é –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Å—Ç–∏–∫–µ—Ä—ã")
            return
            
        elif message.content_type == ContentType.PHOTO:
            logging.info("üì∑ Received photo")
            await message.answer("–Ø –ø–æ–∫–∞ –Ω–µ —É–º–µ—é –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏")
            return
            
        elif message.content_type == ContentType.TEXT:
            await chat_with_gpt(message)
            
        else:
            logging.info(f"‚ùì Received unknown content type: {message.content_type}")
            await message.answer("–≠—Ç–æ—Ç —Ç–∏–ø —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
            
    except Exception as e:
        logging.error(f"‚ùå Error in message handler: {str(e)}")
        await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è")
'''

dp.message.register(start, Command("start"))
dp.message.register(start_new_chat, Command("startnewchat"))
dp.message.register(set_model_command, Command("setmodel"))
dp.message.register(current_model, Command("currentmodel"))
dp.callback_query.register(model_selected)
#dp.message.register(chat_with_gpt)
# –ò—Å–ø–æ–ª—å–∑—É–µ–º ChatType –Ω–∞–ø—Ä—è–º—É—é
dp.message.register(chat_with_gpt, lambda message: message.chat.type in [ChatType.PRIVATE, ChatType.GROUP, ChatType.SUPERGROUP])
#dp.message.register(handle_messages)

async def main():
    logging.info("Starting bot...")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())