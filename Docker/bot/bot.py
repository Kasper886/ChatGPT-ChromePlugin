import asyncio
import logging
import openai
import os
from datetime import datetime
from flask import Flask
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message
from aiogram.filters import Command, CommandStart
from aiogram.enums import ContentType
from dotenv import load_dotenv
from models_list import AVAILABLE_MODELS

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('bot.log')
    ]
)
logger = logging.getLogger(__name__)

try:
    # Load environment variables
    load_dotenv()

    TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

    if not TELEGRAM_BOT_TOKEN:
        raise ValueError("TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
    if not OPENAI_API_KEY:
        raise ValueError("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")

    # Initialize bot and dispatcher
    bot = Bot(token=TELEGRAM_BOT_TOKEN)
    dp = Dispatcher()

    # Configure OpenAI
    openai.api_key = OPENAI_API_KEY

    # Constants
    SELECTED_MODEL_FILE = "selected_model.txt"
    DEFAULT_MODEL = "gpt-3.5-turbo"

    # Global variables
    current_chat_file = None
    
except Exception as e:
    logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {str(e)}")
    raise

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
async def create_new_chat_file():
    try:
        global current_chat_file
        timestamp = datetime.now().strftime("chat-%d-%m-%y-%H-%M-%S.txt")
        current_chat_file = timestamp
        with open(current_chat_file, "w", encoding='utf-8') as f:
            f.write("Chat started\n")
        logger.info(f"New chat file created: {current_chat_file}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞ —á–∞—Ç–∞: {str(e)}")
        raise

async def append_to_chat_file(text):
    try:
        if current_chat_file:
            with open(current_chat_file, "a", encoding='utf-8') as f:
                f.write(text + "\n")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª —á–∞—Ç–∞: {str(e)}")

async def save_selected_model(model_name):
    try:
        with open(SELECTED_MODEL_FILE, "w", encoding='utf-8') as f:
            f.write(model_name)
        logger.info(f"‚úÖ Model {model_name} saved.")
    except Exception as e:
        logger.error(f"‚ùå Error saving model: {str(e)}")

async def load_selected_model():
    try:
        if os.path.exists(SELECTED_MODEL_FILE):
            with open(SELECTED_MODEL_FILE, "r", encoding='utf-8') as f:
                model = f.read().strip()
                if model in AVAILABLE_MODELS:
                    return model
        return DEFAULT_MODEL
    except Exception as e:
        logger.error(f"‚ùå Error loading model: {str(e)}")
        return DEFAULT_MODEL

def clean_message(text: str) -> str:
    if not text:
        return ""
    try:
        unwanted_phrases = [
            "–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
            "Voice message",
            "–ê—É–¥–∏–æ—Å–æ–æ–±—â–µ–Ω–∏–µ",
            "Audio message",
        ]
        for phrase in unwanted_phrases:
            text = text.replace(phrase, "").strip()
        return text if text else ""
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {str(e)}")
        return ""

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥
@dp.message(CommandStart())
async def cmd_start(message: Message):
    try:
        await message.answer("–ü—Ä–∏–≤–µ—Ç! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /startnewchat –¥–ª—è –Ω–∞—á–∞–ª–∞ –Ω–æ–≤–æ–≥–æ —á–∞—Ç–∞.")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ –∫–æ–º–∞–Ω–¥–µ start: {str(e)}")

@dp.message(Command("startnewchat"))
async def start_new_chat(message: Message):
    try:
        await create_new_chat_file()
        timestamp = datetime.now().strftime("%d.%m.%Y %H:%M:%S")
        await message.answer(f"üÜï –ù–æ–≤–∞—è —Å–µ—Å—Å–∏—è –Ω–∞—á–∞—Ç–∞: {timestamp}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ startnewchat: {str(e)}")
        await message.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –Ω–æ–≤–æ–≥–æ —á–∞—Ç–∞")

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def chat_with_gpt(message: Message):
    try:
        logger.info(f"–í—Ö–æ–¥—è—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {message.from_user.id}: {message.text}")

        if not message.text:
            await message.answer("‚ùå –ü—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")
            return

        user_message = clean_message(message.text)
        if not user_message:
            await message.answer("‚ùå –°–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return

        if not current_chat_file or not os.path.exists(current_chat_file):
            await message.answer("‚ùå –ù–∞—á–Ω–∏—Ç–µ –Ω–æ–≤—ã–π —á–∞—Ç –∫–æ–º–∞–Ω–¥–æ–π /startnewchat")
            return

        selected_model = await load_selected_model()
        client = openai.OpenAI(api_key=OPENAI_API_KEY)

        messages = []
        try:
            with open(current_chat_file, "r", encoding='utf-8') as f:
                for line in f:
                    if line.startswith("User:"):
                        content = clean_message(line.replace("User: ", "").strip())
                        if content:
                            messages.append({"role": "user", "content": content})
                    elif line.startswith("Bot:"):
                        content = line.replace("Bot: ", "").strip()
                        if content:
                            messages.append({"role": "assistant", "content": content})
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞: {str(e)}")
            messages = []

        messages.append({"role": "user", "content": user_message})

        response = client.chat.completions.create(
            model=selected_model,
            messages=messages
        )

        bot_response = response.choices[0].message.content
        actual_model = response.model

        await append_to_chat_file(f"User: {user_message}")
        await append_to_chat_file(f"Bot: {bot_response}")

        await message.answer(f"(üîπ Model: {actual_model})\n{bot_response}")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ chat_with_gpt: {str(e)}")
        await message.answer(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")

# –û–±—â–∏–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
@dp.message()
async def handle_messages(message: Message):
    try:
        if message.content_type == ContentType.TEXT:
            if not message.text.startswith('/'):
                await chat_with_gpt(message)
        else:
            logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ —Ç–∏–ø–∞: {message.content_type}")
            await message.answer("‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ handle_messages: {str(e)}")
        await message.answer("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è")

async def main():
    try:
        logger.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
        await dp.start_polling(bot)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –±–æ—Ç–∞: {str(e)}")
        raise

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        logger.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        raise
